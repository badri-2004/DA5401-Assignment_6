{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9047a2",
   "metadata": {},
   "source": [
    "# DA5401 Assignment 6 : Imputation via Regression for Missing Data\n",
    "## Name : R M Badri Narayanan\n",
    "## Roll No : ME22B225"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90a8cf",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0db452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e1d1f",
   "metadata": {},
   "source": [
    "# Part A : Data Preprocessing and Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9706274",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "Here im introducing 7 percent MARs in AGE and BILL_AMT1 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667e2c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('UCI_Credit_Card.csv')\n",
    "\n",
    "df.rename(columns={'default.payment.next.month': 'DEFAULT'}, inplace=True)\n",
    "\n",
    "n_samples = df.shape[0]\n",
    "n_missing = int(n_samples * 0.07)\n",
    "missing_indices_AGE = np.random.choice(df.index, n_missing, replace=False)\n",
    "missing_indices_BILL_AMT1 = np.random.choice(df.index, n_missing, replace=False)\n",
    "missing_indices_BILL_AMT2 = np.random.choice(df.index, n_missing, replace=False)\n",
    "df.loc[missing_indices_AGE, 'AGE'] = np.nan\n",
    "df.loc[missing_indices_BILL_AMT1,'BILL_AMT1'] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f40be",
   "metadata": {},
   "source": [
    "## 2. Imputation Strategy 1: Simple Imputation (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a00d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df.copy()\n",
    "\n",
    "age_median = df_a['AGE'].median()\n",
    "bill_amt1_median = df_a['BILL_AMT1'].median()\n",
    "\n",
    "df_a['AGE'].fillna(age_median, inplace=True)\n",
    "df_a['BILL_AMT1'].fillna(bill_amt1_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4431c04",
   "metadata": {},
   "source": [
    "By using Median imputation, We are trying to observe the central tendency of the data. Mean being based on the sum of all values, is heaviy influenced by extreme values. Median on the other hand being the middle element after ordering the values is not affected by extreme values and acts as a much better measure of central tendency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72172049",
   "metadata": {},
   "source": [
    "## 3. Imputation Strategy 2: Regression Imputation (Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39967f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = df.copy()\n",
    "\n",
    "impute_df = df_b.drop(columns=['ID', 'DEFAULT'])\n",
    "features = [col for col in impute_df.columns if col != 'BILL_AMT1']\n",
    "\n",
    "train_impute = impute_df[impute_df['BILL_AMT1'].notna() & impute_df['AGE'].notna()]\n",
    "predict_impute = impute_df[impute_df['BILL_AMT1'].isna() & impute_df['AGE'].notna()]\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_impute[features], train_impute['BILL_AMT1'])\n",
    "\n",
    "predicted_bill_amt = lr.predict(predict_impute[features])\n",
    "df_b.loc[df_b['BILL_AMT1'].isna() & df_b['AGE'].notna(), 'BILL_AMT1'] = predicted_bill_amt\n",
    "\n",
    "\n",
    "df_b = df_b[df_b['AGE'].notna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db22496",
   "metadata": {},
   "source": [
    "We make prediction of the missing value column using everything else except itself. So the obvious underlying assumption is that the missing value column is not 'Autocorrelated'. For example, here BILL_AMT1 depends only on other features and not on itself (i.e an earlier value of BILL_AMT1 doesnot affect a later value.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54cbc08",
   "metadata": {},
   "source": [
    "## 4. Imputation Strategy 3: Regression Imputation (Non-Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c490814",
   "metadata": {},
   "source": [
    "Used KNN imputation here with k = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4adc7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df.copy()\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5) \n",
    "knn.fit(train_impute[features], train_impute['BILL_AMT1'])\n",
    "\n",
    "\n",
    "predicted_bill_amt_knn = knn.predict(predict_impute[features])\n",
    "df_c.loc[df_c['BILL_AMT1'].isna() & df_c['AGE'].notna(), 'BILL_AMT1'] = predicted_bill_amt_knn\n",
    "\n",
    "df_c = df_c[df_c['AGE'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa2a1fe",
   "metadata": {},
   "source": [
    "# Part B : Model Training and Performance Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc78bf1",
   "metadata": {},
   "source": [
    "## 1. Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f0e34",
   "metadata": {},
   "source": [
    "### Creating dataset D by dropping all NULL value columns and splitting every dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6116f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = df.dropna()\n",
    "\n",
    "target_col = 'DEFAULT'\n",
    "feature_cols = [col for col in df.columns if col not in ['ID', 'DEFAULT']]\n",
    "\n",
    "datasets = {'A': df_a, 'B': df_b, 'C': df_c, 'D': df_d}\n",
    "splits = {}\n",
    "\n",
    "for name, df_clean in datasets.items():\n",
    "    X = df_clean[feature_cols]\n",
    "    y = df_clean[target_col]\n",
    "    splits[name] = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7585c676",
   "metadata": {},
   "source": [
    "## 2. Classifier Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14c075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in datasets.keys():\n",
    "    X_train, X_test, y_train, y_test = splits[name]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    splits[name] = (X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc4bfe",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1075b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classification Report for Model A ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4673\n",
      "           1       0.73      0.25      0.38      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.78      0.61      0.63      6000\n",
      "weighted avg       0.80      0.81      0.78      6000\n",
      "\n",
      "--- Classification Report for Model B ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4347\n",
      "           1       0.69      0.24      0.35      1233\n",
      "\n",
      "    accuracy                           0.81      5580\n",
      "   macro avg       0.75      0.60      0.62      5580\n",
      "weighted avg       0.79      0.81      0.77      5580\n",
      "\n",
      "--- Classification Report for Model C ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4347\n",
      "           1       0.71      0.23      0.35      1233\n",
      "\n",
      "    accuracy                           0.81      5580\n",
      "   macro avg       0.76      0.60      0.62      5580\n",
      "weighted avg       0.79      0.81      0.77      5580\n",
      "\n",
      "--- Classification Report for Model D ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      4037\n",
      "           1       0.78      0.25      0.37      1150\n",
      "\n",
      "    accuracy                           0.82      5187\n",
      "   macro avg       0.80      0.61      0.63      5187\n",
      "weighted avg       0.81      0.82      0.78      5187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name in datasets.keys():\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = splits[name]\n",
    "    log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    log_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = log_reg.predict(X_test_scaled)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = report\n",
    "    \n",
    "    print(f\"--- Classification Report for Model {name} ---\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943cec9d",
   "metadata": {},
   "source": [
    "# Part C: Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471146a1",
   "metadata": {},
   "source": [
    "## 1. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a25ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model  Accuracy  F1-Score (Class 0)  F1-Score (Class 1)  Macro Avg F1  Weighted Avg F1\n",
      "Model A      0.81                0.89                0.38          0.63             0.78\n",
      "Model B      0.81                0.89                0.35          0.62             0.77\n",
      "Model C      0.81                0.89                0.35          0.62             0.77\n",
      "Model D      0.82                0.89                0.37          0.63             0.78\n"
     ]
    }
   ],
   "source": [
    "summary_data = []\n",
    "\n",
    "for name, report in results.items():\n",
    "\n",
    "    accuracy = report[\"accuracy\"]\n",
    "    f1_class0 = report[\"0\"][\"f1-score\"]\n",
    "    f1_class1 = report[\"1\"][\"f1-score\"]\n",
    "    macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "    weighted_f1 = report[\"weighted avg\"][\"f1-score\"]\n",
    "    \n",
    "    summary_data.append({\n",
    "        \"Model\": f\"Model {name}\",\n",
    "        \"Accuracy\": round(accuracy, 2),\n",
    "        \"F1-Score (Class 0)\": round(f1_class0, 2),\n",
    "        \"F1-Score (Class 1)\": round(f1_class1, 2),\n",
    "        \"Macro Avg F1\": round(macro_f1, 2),\n",
    "        \"Weighted Avg F1\": round(weighted_f1, 2)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "\n",
    "summary_df = summary_df.sort_values(by=\"Model\").reset_index(drop=True)\n",
    "\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea5db0",
   "metadata": {},
   "source": [
    "## 2. Efficacy Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d7a395",
   "metadata": {},
   "source": [
    "### Trade-off Between Listwise Deletion and Imputation\n",
    "\n",
    "#### Listwise Deletion (Model D):\n",
    "Removes all rows containing missing values, reducing sample size (5187 vs. 6000).\n",
    "\n",
    "- Advantage: Training data are complete and consistent.\n",
    "\n",
    "- Drawback: Loss of valuable information, especially if missingness is not random, which may bias the model or harm generalization.\n",
    "\n",
    "#### Imputation (Models A–C):\n",
    "Retains the full dataset by filling in missing values.\n",
    "\n",
    "- Advantage: Preserves sample diversity and class balance.\n",
    "\n",
    "- Drawback: Introduces estimation noise that can distort true feature relationships.\n",
    "Despite this, imputation usually yields comparable or slightly better overall F1-scores because it avoids shrinking the dataset.\n",
    "\n",
    "Hence, even though imputation may add noise, Model D can still perform poorly if critical data are deleted—particularly when the dropped samples contain rare but important patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7edba2",
   "metadata": {},
   "source": [
    "### Linear vs. Non-Linear Regression Imputation\n",
    "\n",
    "Model B (Linear) and Model C (Non-Linear) show nearly identical performance.\n",
    "\n",
    "Theoretically, non-linear regression should capture more complex dependencies between predictors and the imputed variable (BILL_AMT1).\n",
    "\n",
    "The negligible difference (F1 ≈ 0.35 for Class 1) suggests that:\n",
    "\n",
    "- The relationship between predictors and BILL_AMT1 is approximately linear,\n",
    " \n",
    " \n",
    "    or\n",
    "\n",
    "- Other variables dominate model performance (Variables other than BILL_AMT1), limiting the benefit of non-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c13bf9",
   "metadata": {},
   "source": [
    "### Recommendation\n",
    "\n",
    "Based on both performance metrics and conceptual considerations, the best strategy for handling missing data in this scenario is Median Imputation (Model A).\n",
    "\n",
    "Although regression-based imputations (Models B and C) attempt to capture relationships between variables, they introduce model-dependent noise without yielding any measurable improvement in F1-scores. Listwise Deletion (Model D), while producing similar accuracy, discards valuable data and risks bias due to reduced sample diversity.\n",
    "\n",
    "Median Imputation offers the most reliable balance — it is simple, robust, and performs marginally better in minority-class detection (F1 = 0.38) while maintaining full dataset integrity. This approach avoids unnecessary model complexity and ensures consistent, interpretable results across different data splits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
